{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming Text into Features for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../bookReviews.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Positive Review'] \n",
    "X = df['Review']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500     There is a reason this book has sold over 180,...\n",
       "1047    There is one thing that every cookbook author ...\n",
       "1667    Being an engineer in the aerospace industry I ...\n",
       "1646    I have no idea how this book has received the ...\n",
       "284     It is almost like dream comes true when I saw ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=1234)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF to transform Text into Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 18558: \n",
      "[('there', 16673), ('is', 9043), ('reason', 13533), ('this', 16714), ('book', 2189), ('has', 7803), ('sold', 15423), ('over', 11793), ('180', 73), ('000', 1), ('copies', 3867), ('it', 9076), ('gets', 7240), ('right', 14207), ('to', 16835), ('the', 16627), ('point', 12568), ('accompanies', 444), ('each', 5372), ('strategy', 15943), ('with', 18277), ('visual', 17844), ('aid', 750), ('so', 15386), ('you', 18497), ('can', 2604), ('get', 7239), ('mental', 10534), ('picture', 12402), ('in', 8491), ('your', 18501), ('head', 7844), ('further', 7051), ('its', 9088), ('section', 14743), ('on', 11601), ('analyzing', 974), ('stocks', 15886), ('and', 984), ('commentary', 3384), ('state', 15782), ('of', 11543), ('financial', 6568), ('statements', 15786), ('market', 10286), ('are', 1220), ('money', 10863), ('if', 8336), ('just', 9282), ('starting', 15774)]\n",
      "\n",
      "[[0.         0.16185315 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01923341 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a TfidfVectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Fit the vectorizer to X_train\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# 3. Print the first 50 items in the vocabulary\n",
    "print(\"Vocabulary size {0}: \".format(len(tfidf_vectorizer.vocabulary_)))\n",
    "print(str(list(tfidf_vectorizer.vocabulary_.items())[0:50])+'\\n')\n",
    "\n",
    "      \n",
    "# 4. Transform *both* the training and test data using the fitted vectorizer and its 'transform' attribute\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# 5. Print the matrix\n",
    "print(X_train_tfidf.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a logistic regression model to the transformed training data + model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the test data: 0.9146\n",
      "The size of the feature space: 18558\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('there', 16673), ('is', 9043), ('reason', 13533), ('this', 16714), ('book', 2189)]:\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "\n",
    "class_label_predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test, probability_predictions)\n",
    "print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "\n",
    "len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "\n",
    "\n",
    "first_five = list(tfidf_vectorizer.vocabulary_.items())[0:5]\n",
    "print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1:\n",
      "\n",
      "I've been a fan of Carol Dweck's scholarly work for years. Her work on self-esteem, self-concept, and the incremental vs. entity theories of intelligence provides some of the most powerfully useful tools I've encountered for educators and parents in their work with children, as well as in their own self-awareness and lives. I'm delighted to see this information written here in such a user-friendly conversational tone, rich with stories that illustrate the nuances and complexities of Dweck's research and ideas. I'm recommending this book to all of my graduate students (teachers and principals working with gifted learners), as well as to parents of high-ability children.\n",
      "\n",
      "Dona Matthews, Ph.D., Director of the Hunter College Center for Gifted Studies and Education, City University of New York\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[124])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[124])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #2:\n",
      "\n",
      "I have read other books by Alesia Holliday and enjoyed them so I looked forward to reading this book.  Unfortunately, I could not get any farther than the first 25 pages.  I even tried diving in further into the book to see if it got better and I still could not read more than 5 pages without turning away.  The best I can do to pin down why I dislike it so much is to say that it tries too hard.  No character seems to even approach reality.  They are all, including the main character and her love interest, over the top\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? False\n",
      "\n",
      "Actual: Is this a good review? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review #2:\\n')\n",
    "print(X_test.to_numpy()[238])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[238])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[238]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min Document Frequency Value: 1\n",
      "AUC on the test data: 0.9268\n",
      "The size of the feature space: 138486\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('there', 119835), ('is', 61671), ('reason', 97323), ('this', 120815), ('book', 18054)]:\n",
      "Glimpse of first 5 stop words \n",
      "[]:\n",
      "\n",
      "Min Document Frequency Value: 10\n",
      "AUC on the test data: 0.9195\n",
      "The size of the feature space: 4023\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('there', 3352), ('is', 1687), ('reason', 2699), ('this', 3396), ('book', 464)]:\n",
      "Glimpse of first 5 stop words \n",
      "['possibly give', 'reading his', 'to montreal', 'prove there', 'books like']:\n",
      "\n",
      "Min Document Frequency Value: 100\n",
      "AUC on the test data: 0.8463\n",
      "The size of the feature space: 257\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('there', 199), ('is', 102), ('this', 207), ('book', 35), ('has', 81)]:\n",
      "Glimpse of first 5 stop words \n",
      "['possibly give', 'reading his', 'to montreal', 'prove there', 'books like']:\n",
      "\n",
      "Min Document Frequency Value: 1000\n",
      "AUC on the test data: 0.6435\n",
      "The size of the feature space: 9\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('is', 3), ('this', 7), ('book', 1), ('it', 4), ('to', 8)]:\n",
      "Glimpse of first 5 stop words \n",
      "['possibly give', 'reading his', 'to montreal', 'prove there', 'books like']:\n"
     ]
    }
   ],
   "source": [
    "for min_df in [1,10,100,1000]:\n",
    "    \n",
    "    print('\\nMin Document Frequency Value: {0}'.format(min_df))\n",
    "    \n",
    "    # 1. Create a TfidfVectorizer object\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=(1,2))\n",
    "\n",
    "    # 2. Fit the vectorizer to X_train\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "    # 3. Transform the training and test data\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # 4. Create a LogisticRegression model object, and fit a Logistic Regression model to the transformed \n",
    "    # training data\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # 5. Make predictions on the transformed test data using the predict_proba() method and save \n",
    "    # the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "    # 6. Compute the Area Under the ROC curve (AUC) for the test data.\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "    # 7. Compute the size of the resulting feature space using the 'vocabulary_' attribute of the vectorizer\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    \n",
    "    # 8. Get a glimpse of the features:\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[0:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "\n",
    "    # 9: Print the first five \"stop words\" - words that we are ignoring\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[0:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
